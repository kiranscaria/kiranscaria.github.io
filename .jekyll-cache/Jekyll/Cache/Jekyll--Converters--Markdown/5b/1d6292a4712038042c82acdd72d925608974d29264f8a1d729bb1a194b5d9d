I"À<p>The <strong>learning rate</strong> or <em>step size</em> in machine learning is a hyperparameter which determines to what extent newly acquired information overrides old information.<sup>[1]</sup> It is the most important hyper-parameter to tune for training deep neural networks. The learning rate is crucial because it controls both the speed of convergence and the ultimate performance of the network. We select learning rate mostly by trial and error, or by virtue of previous experience or some methods like LR finder. A too high learning rate will make the learning jump over minima but a too low learning rate will either take too long to converge or get stuck in undesirable local minima.</p>
:ET